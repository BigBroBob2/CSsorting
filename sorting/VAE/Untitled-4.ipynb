{"cells":[{"cell_type":"markdown","metadata":{},"source":["A simple fix for untitled-3's problem, accuracy same as guessing, the model is really not working."]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":39876,"status":"ok","timestamp":1712020142848,"user":{"displayName":"Zhenyu Xiao","userId":"10865289021779515193"},"user_tz":240},"id":"pb5F2du72SAU","outputId":"fc2542e3-b602-46fd-d83e-e9426c8d72b4"},"outputs":[{"name":"stdout","output_type":"stream","text":["(64, 6122790)\n","[  25351   32967   65124  110605  110614  139796  139803  179850  179858\n","  220048  231137  245534  270780  270789  309584  429010  477457  483625\n","  483633  520625  525407  525415  536316  536324  565340  689253  713584\n","  720463  725368  807271  852387  923113  972713  985866 1009480 1046297\n"," 1052564]\n"]}],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","\n","data_buf = np.load('data.npy')\n","index_buf = np.load('index.npy')\n","data = data_buf[:1055000]\n","index = index_buf[index_buf < 1055000].astype(int) \n","print(data.shape)\n","print(index)"]},{"cell_type":"markdown","metadata":{"id":"NwKZsGa92SAW"},"source":["Sliding Window: try 20ms length (600 samples) and 5ms step (150 samples) for each window?"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":3734,"status":"ok","timestamp":1712020146578,"user":{"displayName":"Zhenyu Xiao","userId":"10865289021779515193"},"user_tz":240},"id":"1cOSG4LE2SAX"},"outputs":[],"source":["# define a sliding window\n","def sliding_window(data, window_size=600, stride=150):\n","    window_data = np.zeros(((len(data)-window_size)//stride, window_size))\n","    index = np.zeros(((len(data)-window_size)//stride, window_size))\n","    for row in range((len(data)-window_size)//stride):\n","        window_data[row, :] = data[row*stride:row*stride+window_size]\n","        index[row, :] = np.arange(row*stride, row*stride+window_size)\n","    return window_data, index\n","\n","windowed_data, windowed_index = sliding_window(data[53, :], window_size=600, stride=150)\n","\n","window_data_low, window_index_low = sliding_window(data[53, :850000], window_size=600, stride=150)\n","window_data_high, window_index_high = sliding_window(data[53, 850000:1055000], window_size=600, stride=150)\n","\n","label = np.zeros(windowed_data.shape[0])\n","for i in range(windowed_data.shape[0]):\n","    if np.any(np.isin(windowed_index[i, :], index)):\n","        label[i] = 1\n","    else:\n","        label[i] = 0\n","        \n","        \n","def make_label(windowed_data, index):\n","    label = np.zeros(windowed_data.shape[0])\n","    for i in range(windowed_data.shape[0]):\n","        if np.any(np.isin(windowed_index[i, :], index)):\n","            label[i] = 1\n","        else:\n","            label[i] = 0\n","    return label\n","\n","label_low = make_label(window_data_low, index)\n","label_high = make_label(window_data_high, index)"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":3983,"status":"ok","timestamp":1712020150741,"user":{"displayName":"Zhenyu Xiao","userId":"10865289021779515193"},"user_tz":240},"id":"TagLskrr2SAX"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","class ConvNet(nn.Module):\n","    def __init__(self):\n","        super(ConvNet, self).__init__()\n","        self.conv1 = nn.Conv1d(in_channels=1, out_channels=16, kernel_size=7, padding='same')\n","        self.bn1 = nn.BatchNorm1d(num_features=16)\n","        self.conv2 = nn.Conv1d(in_channels=16, out_channels=32, kernel_size=5, padding='same')\n","        self.bn2 = nn.BatchNorm1d(num_features=32)\n","        self.conv3 = nn.Conv1d(in_channels=32, out_channels=64, kernel_size=3, padding='same')\n","        self.bn3 = nn.BatchNorm1d(num_features=64)\n","        self.global_avg_pool = nn.AdaptiveAvgPool1d(1)\n","        # fc\n","        self.fc1 = nn.Linear(64, 128)\n","        self.fc2 = nn.Linear(128, 64)\n","        self.fc3 = nn.Linear(64, 1)\n","\n","    def forward(self, x):\n","        x = F.relu(self.bn1(self.conv1(x)))\n","        x = F.relu(self.bn2(self.conv2(x)))\n","        x = F.relu(self.bn3(self.conv3(x)))\n","        x = self.global_avg_pool(x)\n","        x = x.view(x.size(0), -1)\n","        x = F.relu(self.fc1(x))\n","        x = F.relu(self.fc2(x))\n","        x = torch.sigmoid(self.fc3(x))\n","        return x\n","\n","def balance_data(data_tensor, labels):\n","    positive_index = np.where(labels == 1)[0]\n","    negative_index = np.where(labels == 0)[0]\n","    negative_index = np.random.choice(negative_index, size=positive_index.shape[0], replace=False)\n","    balanced_data_tensor = torch.cat((data_tensor[positive_index], data_tensor[negative_index]), dim=0)\n","    balanced_label_tensor = torch.cat((labels[positive_index], labels[negative_index]), dim=0)\n","    return balanced_data_tensor, balanced_label_tensor"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8899,"status":"ok","timestamp":1712020159638,"user":{"displayName":"Zhenyu Xiao","userId":"10865289021779515193"},"user_tz":240},"id":"IJZPWvMc2SAX","outputId":"384c442e-4380-4588-95c8-1bad1990f1f5"},"outputs":[{"name":"stdout","output_type":"stream","text":["torch.Size([186, 1, 600]) torch.Size([50, 1, 600]) torch.Size([186, 1]) torch.Size([50, 1])\n","Epoch 5/40, Loss: 0.016855869442224503\n","Epoch 10/40, Loss: 0.003011260647326708\n","Epoch 15/40, Loss: 0.004418177530169487\n","Epoch 20/40, Loss: 0.005040186457335949\n","Epoch 25/40, Loss: 0.0021974400151520967\n","Epoch 30/40, Loss: 0.000330679293256253\n","Epoch 35/40, Loss: 0.0011856112396344543\n","Epoch 40/40, Loss: 0.00022112971055321395\n","Accuracy on test set: 48.00%\n","Confusion Matrix:\n","[[24  1]\n"," [25  0]]\n","Precision: 0.00\n","Recall: 0.00\n","F1 Score: 0.00\n"]}],"source":["from sklearn.model_selection import train_test_split\n","from torch.utils.data import TensorDataset, DataLoader\n","import torch\n","from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score\n","\n","data_low_tensor = torch.tensor(window_data_low[:, None, :], dtype=torch.float32)\n","data_high_tensor = torch.tensor(window_data_high[:, None, :], dtype=torch.float32)\n","label_low_tensor = torch.tensor(label_low, dtype=torch.float32).unsqueeze(1)\n","label_high_tensor = torch.tensor(label_high, dtype=torch.float32).unsqueeze(1)\n","\n","# data_tensor = torch.tensor(windowed_data[:, None, :], dtype=torch.float32)\n","# label_tensor = torch.tensor(label, dtype=torch.float32).unsqueeze(1)\n","\n","X_train, y_train = balance_data(data_low_tensor, label_low_tensor)\n","X_test, y_test = balance_data(data_high_tensor, label_high_tensor)\n","print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n","\n","# X_train, X_test, y_train, y_test = train_test_split(data_tensor, label_tensor, test_size=0.2, stratify=label_tensor)\n","# print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n","\n","\n","train_dataset = TensorDataset(X_train, y_train)\n","test_dataset = TensorDataset(X_test, y_test)\n","train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n","test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n","\n","# initial model\n","model = ConvNet()\n","criterion = nn.BCELoss()\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n","num_epochs = 40\n","\n","for epoch in range(num_epochs):\n","    model.train()\n","    for inputs, labels in train_loader:\n","        optimizer.zero_grad()\n","        outputs = model(inputs)\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","    if (epoch+1) % 5 == 0:\n","        print(f'Epoch {epoch+1}/{num_epochs}, Loss: {loss.item()}')\n","\n","model.eval()\n","all_predicted = []\n","all_labels = []\n","\n","with torch.no_grad():\n","    for inputs, labels in test_loader:\n","        outputs = model(inputs)\n","        predicted = (outputs.data > 0.5).float()\n","        all_predicted.extend(predicted.view(-1).tolist())\n","        all_labels.extend(labels.view(-1).tolist())\n","\n","accuracy = accuracy_score(all_labels, all_predicted)\n","conf_matrix = confusion_matrix(all_labels, all_predicted)\n","precision = precision_score(all_labels, all_predicted)\n","recall = recall_score(all_labels, all_predicted)\n","f1 = f1_score(all_labels, all_predicted)\n","\n","print(f'Accuracy on test set: {accuracy * 100:.2f}%')\n","print(f'Confusion Matrix:\\n{conf_matrix}')\n","print(f'Precision: {precision:.2f}')\n","print(f'Recall: {recall:.2f}')\n","print(f'F1 Score: {f1:.2f}')"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1712020159638,"user":{"displayName":"Zhenyu Xiao","userId":"10865289021779515193"},"user_tz":240},"id":"PdGp49YZ4Sew"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1712020159638,"user":{"displayName":"Zhenyu Xiao","userId":"10865289021779515193"},"user_tz":240},"id":"O3I0Y1bg2SAY"},"outputs":[],"source":["# import matplotlib.pyplot as plt\n","\n","# plt.figure()\n","# for i in range(len(index)):\n","#     plt.plot(np.arange(0, 600), data[53, index[i]-200:index[i]+400])\n","# plt.show()"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"bds","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.18"}},"nbformat":4,"nbformat_minor":0}
